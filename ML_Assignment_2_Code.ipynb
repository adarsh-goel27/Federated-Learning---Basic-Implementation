{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7zlHdse-iUk",
        "outputId": "710c1e8b-8a82-4a53-82bc-1b3e565aa6e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Custom Dataset Loader\n"
      ],
      "metadata": {
        "id": "VMCOTbGt2hPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import time\n",
        "import os\n",
        "from torchvision import datasets\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Get the list of class labels from subfolder names\n",
        "        self.class_labels = [class_label for class_label in sorted(os.listdir(root_dir))\n",
        "                             if os.path.isdir(os.path.join(root_dir, class_label))]\n",
        "        self.class_to_idx = {class_label: idx for idx, class_label in enumerate(self.class_labels)}\n",
        "\n",
        "        # Build a list of image paths and corresponding labels\n",
        "        self.samples = []\n",
        "        for class_label in self.class_labels:\n",
        "            class_path = os.path.join(root_dir, class_label)\n",
        "            if os.path.isdir(class_path):\n",
        "              for file_name in os.listdir(class_path):\n",
        "                file_path = os.path.join(class_path, file_name)\n",
        "                self.samples.append((file_path, self.class_to_idx[class_label]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "MwFQ07da215p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Custom CNN Model for classification\n",
        "\n"
      ],
      "metadata": {
        "id": "A-O2so3F29XN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# basic CNN image classification model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(64 * 64 * 64, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GU--Hj5q3MvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Centralised Learning"
      ],
      "metadata": {
        "id": "JyUAWU3m8An5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the model\n",
        "model = Net()\n",
        "model.train\n",
        "\n",
        "# Defining the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Defining the optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "          ])\n",
        "\n",
        "# Loading the dataset\n",
        "dataset = CustomDataset(\"/content/drive/MyDrive/ML_Assignment_2/Centralised_Data\", transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Training the model\n",
        "for inputs, labels in dataloader:\n",
        "  outputs = model(inputs)\n",
        "  loss = criterion(outputs, labels)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "id": "j5-OW9CtGQdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "dataset = CustomDataset(\"/content/drive/MyDrive/ML_Assignment_2/Centralised_Data\", transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Calculating the accuracy of the model\n",
        "with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "          outputs = model(inputs)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()"
      ],
      "metadata": {
        "id": "JE48QeK-GXfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_accuracy = correct / total\n",
        "# printing the training accuracy of this epoch of federated learning\n",
        "print(f'Training Accuracy: {100 * training_accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5RkTwFP1Pnf",
        "outputId": "c4b7a27e-4263-4f56-a383-940ac5cf39b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 53.03%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(\"/content/drive/MyDrive/ML_Assignment_2/Test_Data\", transform=transform)\n",
        "dataloader_test = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "correct_test = 0\n",
        "total_test = 0\n",
        "\n",
        "# Calculing the accuracy of the model\n",
        "with torch.no_grad():\n",
        "        for inputs, labels in dataloader_test:\n",
        "          outputs = model(inputs)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total_test += labels.size(0)\n",
        "          correct_test += (predicted == labels).sum().item()"
      ],
      "metadata": {
        "id": "SPP9m6xgDi2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_accuracy = correct_test / total_test\n",
        "# printing the training accuracy of this epoch of federated learning\n",
        "print(f'Testing Accuracy: {100 * testing_accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZVXOvJdDsTR",
        "outputId": "28e3940a-b0b4-47d3-cbfb-a86c5ab5db3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy: 47.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Federated Learning Model"
      ],
      "metadata": {
        "id": "NkJYVdWQoT7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1  Function for selecting clients"
      ],
      "metadata": {
        "id": "kwFBlTDE43Yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to select a client based on fixed criteria\n",
        "def select_client(client):\n",
        "  meta_data_path = os.path.join(client, \"meta.csv\")\n",
        "  meta_data = pd.read_csv(meta_data_path)\n",
        "  if (meta_data['response'][0]>0.25 and meta_data['response'][1]>1.25 and meta_data['response'][2]==1 and meta_data['response'][3]>20):\n",
        "    return True\n",
        "  return False"
      ],
      "metadata": {
        "id": "44Lvd_Ke5C-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Function for aggregating the model weights"
      ],
      "metadata": {
        "id": "BvhIX7fX5G1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to aggregate the weights of different models\n",
        "def average_weights(models):\n",
        "    # Get the number of models\n",
        "    num_models = len(models)\n",
        "\n",
        "    # get the state_dict of the first model\n",
        "    average_state_dict = models[0].state_dict()\n",
        "\n",
        "    # sum up the state_dicts of the remaining models\n",
        "    for i in range(1, num_models):\n",
        "        current_state_dict = models[i].state_dict()\n",
        "        average_state_dict = {name: average_state_dict[name] + current_state_dict[name] for name in average_state_dict}\n",
        "\n",
        "    # average the state_dicts\n",
        "    average_state_dict = {name: param / num_models for name, param in average_state_dict.items()}\n",
        "\n",
        "    return average_state_dict\n"
      ],
      "metadata": {
        "id": "DOgiQ2Rb5PCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Function for Training"
      ],
      "metadata": {
        "id": "b2mafuft5cXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def federated_learning(main_model, epochs, lr, list_of_client_lists):\n",
        "    for epoch in range(epochs):\n",
        "      root_dir_list = []\n",
        "      # select the list of clients registered for the current epoch\n",
        "      client_list = list_of_client_lists[epoch]\n",
        "\n",
        "      # for each epoch select the eligible clients\n",
        "      for client in client_list:\n",
        "        client_path = os.path.join(\"/content/drive/MyDrive/ML_Assignment_2/Federated_Data\", client)\n",
        "        if (select_client(client_path)):\n",
        "          root_dir_list.append(client_path)\n",
        "\n",
        "      models = []\n",
        "\n",
        "      # stimulation of training for each client using a for loop\n",
        "      for root_dir in root_dir_list:\n",
        "            print(root_dir)\n",
        "            model_local = Net()\n",
        "            model_local.load_state_dict(main_model.state_dict())\n",
        "            model_local.train\n",
        "\n",
        "            # define loss function and optimizer\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            optimizer = optim.SGD(model_local.parameters(), lr=lr)\n",
        "\n",
        "            transform = transforms.Compose([\n",
        "                transforms.Resize((256, 256)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "            ])\n",
        "\n",
        "            dataset = CustomDataset(root_dir, transform=transform)\n",
        "            dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "            for inputs, labels in dataloader:\n",
        "                outputs = model_local(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            # appending the model to model list represents that the trained model has been returned by this client\n",
        "            models.append(model_local)\n",
        "\n",
        "      # averaging the weights of all the trained models received from clients in this epoch\n",
        "      main_model.load_state_dict(average_weights(models))\n",
        "\n",
        "      main_model.eval()\n",
        "      correct = 0\n",
        "      total = 0\n",
        "\n",
        "      transform = transforms.Compose([\n",
        "                transforms.Resize((256, 256)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "            ])\n",
        "\n",
        "      dataset = CustomDataset(\"/content/drive/MyDrive/ML_Assignment_2/Centralised_Data\", transform=transform)\n",
        "      dataloader_train = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for inputs, labels in dataloader_train:\n",
        "          outputs = main_model(inputs)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "      training_accuracy = correct / total\n",
        "      # printing the training accuracy of this epoch of federated learning\n",
        "      print(f'Training Accuracy: {100 * training_accuracy:.2f}%')\n",
        "\n",
        "      print(f\"Epoch {epoch+1}/{epochs} completed\")"
      ],
      "metadata": {
        "id": "oYRRM4JN5k3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 Train the model using Federated learning"
      ],
      "metadata": {
        "id": "oe23fuD46xVB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioa3IdorDTnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5226414-57c2-4c36-bccc-d523c53db1dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_1/Client_1\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_1/Client_2\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_1/Client_3\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_1/Client_4\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_1/Client_5\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_1/Client_6\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_1/Client_7\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_1/Client_8\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_1/Client_9\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_1/Client_10\n",
            "Training Accuracy: 34.83%\n",
            "Epoch 1/4 completed\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_2/Client_1\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_2/Client_2\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_2/Client_4\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_2/Client_5\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_2/Client_7\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_2/Client_8\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_2/Client_9\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_2/Client_10\n",
            "Training Accuracy: 47.00%\n",
            "Epoch 2/4 completed\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_3/Client_1\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_3/Client_3\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_3/Client_4\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_3/Client_5\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_3/Client_6\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_3/Client_7\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_3/Client_9\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_3/Client_10\n",
            "Training Accuracy: 44.97%\n",
            "Epoch 3/4 completed\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_4/Client_1\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_4/Client_2\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_4/Client_4\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_4/Client_5\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_4/Client_6\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_4/Client_7\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_4/Client_8\n",
            "/content/drive/MyDrive/ML_Assignment_2/Federated_Data/Epoch_4/Client_10\n",
            "Training Accuracy: 43.30%\n",
            "Epoch 4/4 completed\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Store the location of clients for each round\n",
        "client_list_epoch1 = [\"Epoch_1/Client_1\", \"Epoch_1/Client_2\", \"Epoch_1/Client_3\", \"Epoch_1/Client_4\", \"Epoch_1/Client_5\", \"Epoch_1/Client_6\", \"Epoch_1/Client_7\", \"Epoch_1/Client_8\", \"Epoch_1/Client_9\", \"Epoch_1/Client_10\"]\n",
        "client_list_epoch2 = [\"Epoch_2/Client_1\", \"Epoch_2/Client_2\", \"Epoch_2/Client_3\", \"Epoch_2/Client_4\", \"Epoch_2/Client_5\", \"Epoch_2/Client_6\", \"Epoch_2/Client_7\", \"Epoch_2/Client_8\", \"Epoch_2/Client_9\", \"Epoch_2/Client_10\"]\n",
        "client_list_epoch3 = [\"Epoch_3/Client_1\", \"Epoch_3/Client_2\", \"Epoch_3/Client_3\", \"Epoch_3/Client_4\", \"Epoch_3/Client_5\", \"Epoch_3/Client_6\", \"Epoch_3/Client_7\", \"Epoch_3/Client_8\", \"Epoch_3/Client_9\", \"Epoch_3/Client_10\"]\n",
        "client_list_epoch4 = [\"Epoch_4/Client_1\", \"Epoch_4/Client_2\", \"Epoch_4/Client_3\", \"Epoch_4/Client_4\", \"Epoch_4/Client_5\", \"Epoch_4/Client_6\", \"Epoch_4/Client_7\", \"Epoch_4/Client_8\", \"Epoch_4/Client_9\", \"Epoch_4/Client_10\"]\n",
        "\n",
        "list_of_client_lists = [client_list_epoch1, client_list_epoch2, client_list_epoch3, client_list_epoch4]\n",
        "\n",
        "# Create the model\n",
        "main_model = Net()\n",
        "\n",
        "# Train the model\n",
        "federated_learning(main_model, epochs=4, lr=0.001, list_of_client_lists=list_of_client_lists)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(\"/content/drive/MyDrive/ML_Assignment_2/Test_Data\", transform=transform)\n",
        "dataloader_test = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "main_model.eval()\n",
        "correct_test = 0\n",
        "total_test = 0\n",
        "\n",
        "# Calculing the accuracy of the model\n",
        "with torch.no_grad():\n",
        "        for inputs, labels in dataloader_test:\n",
        "          outputs = main_model(inputs)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total_test += labels.size(0)\n",
        "          correct_test += (predicted == labels).sum().item()"
      ],
      "metadata": {
        "id": "duc7TOraEDCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_accuracy = correct_test / total_test\n",
        "# printing the training accuracy of this epoch of federated learning\n",
        "print(f'Testing Accuracy: {100 * testing_accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNLv-VNyEDpl",
        "outputId": "d0aaf3e2-3691-4932-dbfb-fa75b436cb6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy: 41.33%\n"
          ]
        }
      ]
    }
  ]
}